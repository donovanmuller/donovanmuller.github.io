<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>8.&nbsp;Deploying Streams on OpenShift</title><link rel="stylesheet" type="text/css" href="css/manual-multipage.css"><meta name="generator" content="DocBook XSL Stylesheets V1.78.1"><link rel="home" href="index.html" title="Spring Cloud Data Flow Server for OpenShift"><link rel="up" href="getting-started.html" title="Part&nbsp;III.&nbsp;Getting Started"><link rel="prev" href="getting-started.html" title="Part&nbsp;III.&nbsp;Getting Started"><link rel="next" href="_deploying_tasks_on_openshift.html" title="9.&nbsp;Deploying Tasks on OpenShift"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">8.&nbsp;Deploying Streams on OpenShift</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="getting-started.html">Prev</a>&nbsp;</td><th width="60%" align="center">Part&nbsp;III.&nbsp;Getting Started</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="_deploying_tasks_on_openshift.html">Next</a></td></tr></table><hr></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a name="_deploying_streams_on_openshift" href="#_deploying_streams_on_openshift"></a>8.&nbsp;Deploying Streams on OpenShift</h2></div></div></div><p>The following guide assumes that you have a OpenShift 3 cluster available. This includes both <a class="link" href="https://www.openshift.org/" target="_top">OpenShift Origin</a>
and <a class="link" href="https://www.openshift.com/container-platform/" target="_top">OpenShift Container Platform</a> offerings.</p><p>If you do not have a OpenShift cluster available, see the next section which describes running a local OpenShift Origin cluster for development/testing
otherwise continue to <a class="xref" href="_deploying_streams_on_openshift.html#templates" title="8.3&nbsp;Installing the Data Flow Server using OpenShift templates">Section&nbsp;8.3, &#8220;Installing the Data Flow Server using OpenShift templates&#8221;</a>.</p><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_a_local_openshift_cluster_with_minishift" href="#_a_local_openshift_cluster_with_minishift"></a>8.1&nbsp;A local OpenShift cluster with minishift</h2></div></div></div><p>There are a few ways to stand up a local OpenShift Origin cluster on your machine for testing.
These include:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><a class="link" href="https://github.com/openshift/origin/blob/master/docs/cluster_up_down.md" target="_top"><code class="literal">oc cluster up</code></a></li><li class="listitem"><a class="link" href="https://www.openshift.org/vm/" target="_top">All-In-One VM</a></li><li class="listitem"><a class="link" href="https://github.com/minishift/minishift" target="_top">minishift</a></li><li class="listitem">and others</li></ul></div><p>For the purpose of this guide, the <a class="link" href="https://github.com/minishift/minishift" target="_top">minishift</a> tool will be used.</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_installation_and_getting_started" href="#_installation_and_getting_started"></a>8.1.1&nbsp;Installation and Getting Started</h3></div></div></div><p>Install minishift as per the instructions <a class="link" href="https://github.com/minishift/minishift#installation" target="_top">here</a>.
Once you have installed minishift successfully, you can start up a OpenShift instance with <code class="literal">minishift start</code>.</p><pre class="programlisting">$ minishift start --memory 4096 --cpus 4 --deploy-router
Starting local OpenShift cluster...
oc is now configured to use the cluster.
Run this command to use the cluster:
oc login --username=admin --password=admin
$</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The <code class="literal">--deploy-router</code> option deploys the default <a class="link" href="https://docs.openshift.org/latest/install_config/router/default_haproxy_router.html" target="_top">HAProxy Router</a>
which is required to expose and access the Spring Cloud Data Flow UI and other tools.</p></td></tr></table></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_openshift_console" href="#_openshift_console"></a>OpenShift Console</h4></div></div></div><p>The OpenShift Console is a valuable interface into your cluster, it is recommended that you open the console with:</p><pre class="programlisting">$ minishift console
Opening OpenShift console in default browser...
$</pre><p>a browser window will open with the console login page. Login with <code class="literal">admin</code>/<code class="literal">admin</code> credentials.</p><div class="informalfigure"><div class="mediaobject"><img src="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/raw/master/spring-cloud-dataflow-server-openshift-docs/src/main/asciidoc/images/scdf-openshift-console.png" alt="OpenShift Console"></div></div><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/important.png"></td><th align="left">Important</th></tr><tr><td align="left" valign="top"><p>Make sure you wait for the <code class="literal">docker-registry</code> and <code class="literal">router</code> deployments to successfully deploy before continuing.
These resources are deployed to the <code class="literal">default</code> project.</p></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="__literal_oc_literal_cli_tool" href="#__literal_oc_literal_cli_tool"></a><code class="literal">oc</code> CLI tool</h4></div></div></div><p>You can also manage the local cluster with the <code class="literal">oc</code> CLI tool.
If you do not have the <code class="literal">oc</code> tool installed, follow the instructions <a class="link" href="https://docs.openshift.org/latest/cli_reference/get_started_cli.html" target="_top">here</a>.</p><p>Login and use the local instance with:</p><pre class="programlisting">$ oc login --username=admin --password=admin
Login successful.

You have access to the following projects and can switch between them with 'oc project &lt;projectname&gt;':

  * default
    kube-system
    openshift
    openshift-infra

Using project "default".
$</pre></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_creating_a_new_project" href="#_creating_a_new_project"></a>8.2&nbsp;Creating a new Project</h2></div></div></div><p>To group the resources created as part of this guide, create a new Project.
You can do this using the Console or <code class="literal">oc</code> tool. Below is an example using the 'oc' tool:</p><pre class="programlisting">$ oc new-project scdf --description="Spring Cloud Data Flow"
Now using project "scdf" on server "https://192.168.64.13:8443".
...
$</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The IP address (192.168.64.13) assigned will vary each time you use <code class="literal">minishift start</code>, so adjust accordingly.
The active project should be <code class="literal">scdf</code> (check with <code class="literal">oc project</code>) and should be the project used for the rest of this guide.</p></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="templates" href="#templates"></a>8.3&nbsp;Installing the Data Flow Server using OpenShift templates</h2></div></div></div><p>To install a Data Flow Server and supporting infrastructure components to OpenShift, we will use <a class="link" href="https://docs.openshift.org/latest/dev_guide/templates.html" target="_top">OpenShift templates</a>.
Templates allow you to deploy a predefined set of resources with sane default configurations which can be optionally configured via parameters for specific environments.</p><p>The templates for the Data Flow Server for OpenShift are available in the <a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/tree/v1.1.0.RELEASE/src/etc/openshift" target="_top"><code class="literal">src/etc/openshift</code></a>
directory in this project&#8217;s <a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift" target="_top">GitHub repository</a>.
There are several templates available:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/tree/v1.1.0.RELEASE/src/etc/openshift/scdf-template.yaml" target="_top">Data Flow Server only</a> -
This template only deploys the Spring Cloud Data Flow Server for OpenShift and no other resources.
This template provides the capability to provide the configuration for Spring Cloud Stream binder implementation, RDBMS and Redis resources with sane defaults. This template is suited for
environments where these existing resources are already deployed.</li><li class="listitem"><a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/tree/v1.1.0.RELEASE/src/etc/openshift/scdf-ephemeral-datasources-template.yaml" target="_top">Data Flow Server with ephemeral Datasources</a> -
Deploys Data Flow Server for OpenShift as well as MySQL and Redis containers without persistent volumes.
I.e. the data persisted by these containers will be lost on restart.</li><li class="listitem"><a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/tree/v1.1.0.RELEASE/src/etc/openshift/scdf-ephemeral-datasources-kafka-template.yaml" target="_top">Data Flow Server with ephemeral Datasources and Kafka binder</a> -
Same as above but with an additional Kafka instance for use as the Spring Cloud Stream binder implementation.</li><li class="listitem"><a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/tree/v1.1.0.RELEASE/src/etc/openshift/scdf-ephemeral-datasources-rabbitmq-template.yaml" target="_top">Data Flow Server with ephemeral Datasources and RabbitMQ binder</a> -
Same as above but with a RabbitMQ instance for use as the binder implementation.</li></ul></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_installing_the_openshift_templates" href="#_installing_the_openshift_templates"></a>8.3.1&nbsp;Installing the OpenShift templates</h3></div></div></div><p>You can install the above templates using the OpenShift Console or <code class="literal">oc</code> tool.
You would have to clone or download the <a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift" target="_top">Data Flow Server for OpenShift</a> project and
import the templates in the <code class="literal">src/etc/openshift</code> directory one by one using the Console or <code class="literal">oc create -f &#8230;&#8203;</code>.</p><p>However, a more convenient and the recommended way of installing all the templates is to run the following:</p><pre class="programlisting">$ curl https://raw.githubusercontent.com/donovanmuller/spring-cloud-dataflow-server-openshift/v1.1.0.RELEASE/src/etc/openshift/install-templates.sh | bash
Installing OpenShift templates into project 'scdf'...
Archive:  /tmp/scdf-openshift-templates.zip
  inflating: /tmp/scdf-openshift-templates/scdf-ephemeral-datasources-kafka-template.yaml
  inflating: /tmp/scdf-openshift-templates/scdf-ephemeral-datasources-rabbitmq-template.yaml
  inflating: /tmp/scdf-openshift-templates/scdf-ephemeral-datasources-template.yaml
  inflating: /tmp/scdf-openshift-templates/scdf-sa.yaml
  inflating: /tmp/scdf-openshift-templates/scdf-template.yaml
Installing template '/tmp/scdf-openshift-templates/scdf-ephemeral-datasources-kafka-template.yaml'
template "spring-cloud-dataflow-server-openshift-ephemeral-kafka" replaced
Installing template '/tmp/scdf-openshift-templates/scdf-ephemeral-datasources-rabbitmq-template.yaml'
template "spring-cloud-dataflow-server-openshift-ephemeral-rabbitmq" replaced
Installing template '/tmp/scdf-openshift-templates/scdf-ephemeral-datasources-template.yaml'
template "spring-cloud-dataflow-server-openshift-ephemeral-datasources" replaced
Installing template '/tmp/scdf-openshift-templates/scdf-sa.yaml'
serviceaccount "scdf" replaced
Installing template '/tmp/scdf-openshift-templates/scdf-template.yaml'
template "spring-cloud-dataflow-server-openshift" replaced
Adding 'edit' role to 'scdf' Service Account...
Adding 'scdf' Service Account to the 'anyuid' SCC...
Templates installed.
$</pre><p>This will download all the templates and install them into the <code class="literal">scdf</code> project by default. It will also create and
configure a required Service Account mentioned below.
The project can be specified by using <code class="literal">-s scdf</code> after the <code class="literal">bash</code> command above.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_creating_and_configuring_service_accounts" href="#_creating_and_configuring_service_accounts"></a>8.3.2&nbsp;Creating and configuring Service Accounts</h3></div></div></div><p>The Data Flow Server requires a <a class="link" href="https://docs.openshift.org/latest/dev_guide/service_accounts.html" target="_top">Service Account</a> (named <code class="literal">scdf</code>),
which grants it access to perform actions such as reading ConfigMaps and Secrets, creating Builds, etc.</p><p>To create the <code class="literal">scdf</code> Service Account, use the <code class="literal">oc</code> tool from the <code class="literal">src/etc/openshift</code> directory:</p><pre class="programlisting">$ oc create -f scdf-sa.yaml
...</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If you used the <code class="literal">install-templates.sh</code> script above to install the templates, the <code class="literal">scdf</code>
Service Account would have already been created for you.</p></td></tr></table></div><p>The <code class="literal">scdf</code> Service Account must have the <code class="literal">edit</code> <a class="link" href="https://docs.openshift.org/latest/admin_guide/manage_authorization_policy.html#viewing-roles-and-bindings" target="_top">role</a>
added to it in order to have the correct permissions to function properly.
Add the <code class="literal">edit</code> role with the following:</p><pre class="programlisting">$ oc policy add-role-to-user edit system:serviceaccount:scdf:scdf
...</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If you used the <code class="literal">install-templates.sh</code> script above to install the templates, the <code class="literal">scdf</code>
Service Account would already have the <code class="literal">edit</code> role added to it.</p></td></tr></table></div><p>The <code class="literal">scdf</code> Service Account also needs to be added to the <code class="literal">anyuid</code> Security Context Constraint to allow the MySQL
Pod to run using the <a class="link" href="https://docs.openshift.org/latest/admin_guide/manage_scc.html#enable-dockerhub-images-that-require-root" target="_top"><code class="literal">root</code> user</a>.
By default OpenShift starts a Pod using a random user Id. Add the Service Account to the <code class="literal">anyuid</code> SCC group with:</p><pre class="programlisting">$ oc adm policy add-scc-to-user anyuid system:serviceaccount:scdf:scdf</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If you used the <code class="literal">install-templates.sh</code> script above to install the templates, the <code class="literal">scdf</code>
Service Account is already added to the <code class="literal">anyuid</code> SCC.</p></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_installing_the_data_flow_server" href="#_installing_the_data_flow_server"></a>8.3.3&nbsp;Installing the Data Flow Server</h3></div></div></div><p>For this guide we&#8217;ll use the <a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/tree/v1.1.0.RELEASE/src/etc/openshift/scdf-ephemeral-datasources-kafka-template.yaml" target="_top">Data Flow Server with ephemeral Datasources and Kafka binder</a>
template to start a Data Flow Server in the <code class="literal">scdf</code> project.
First, using the OpenShift Console, click the <span class="emphasis"><em>Add to Project</em></span> button. You should see the list of templates mentioned above.
Choose the <code class="literal">spring-cloud-dataflow-server-openshift-ephemeral-kafka</code> template.</p><div class="informalfigure"><div class="mediaobject"><img src="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/raw/master/spring-cloud-dataflow-server-openshift-docs/src/main/asciidoc/images/scdf-openshift-templates.png" alt="Data Flow Server template"></div></div><p>Default configuration values are provided but can be updated to meet your needs if necessary.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>To avoid deployments failing due to long image pull times, you can manually pull the requires images.
Note that you should first change your local Docker client to use the Docker engine in the minishift VM</p><pre class="programlisting">$ eval $(minishift docker-env)
$ curl https://raw.githubusercontent.com/donovanmuller/spring-cloud-dataflow-server-openshift/v1.1.0.RELEASE/src/etc/openshift/pull-images.sh | bash</pre><p>The above step is optional as OpenShift will also pull the required images. However, depending on your network speed, deployments may fail
due to timeout. If this happens, simply start another deployment of the component by click the <span class="emphasis"><em>Deploy</em></span> button when viewing the deployment.</p></td></tr></table></div><p>After updating the configuration values or leaving the default values, click the <span class="emphasis"><em>Create</em></span> button to deploy this template.</p><p>Pulling the various Docker images may take some time, so please be patient.
Once all the images have been pulled, the various pods will start and should all appear as dark blue circles.</p><div class="informalfigure"><div class="mediaobject"><img src="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/raw/master/spring-cloud-dataflow-server-openshift-docs/src/main/asciidoc/images/scdf-openshift-deployed.png" alt="Data Flow Server deployed"></div></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The Data Flow Server will by default deploy apps only in the project that it itself is deployed. I.e. a Data Flow Server
deployed in the <code class="literal">default</code> project will not be able to deploy applications to the <code class="literal">scdf</code> project. The recommended configuration
is a Data Flow Server per project.</p></td></tr></table></div><p>Verify that the Data Flow Server has started successfully by clicking on the exposed <a class="link" href="https://docs.openshift.org/latest/dev_guide/routes.html" target="_top">Route</a> URL.</p><div class="informalfigure"><div class="mediaobject"><img src="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/raw/master/spring-cloud-dataflow-server-openshift-docs/src/main/asciidoc/images/scdf-openshift-dashboard.png" alt="Data Flow Server UI"></div></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The UI is mapped to <code class="literal">/dashboard</code></p></td></tr></table></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Tip"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Tip]" src="images/tip.png"></td><th align="left">Tip</th></tr><tr><td align="left" valign="top"><p>If you&#8217;d like to reset or perhaps try another template, you can remove the Data Flow Server and other
resources created by the template with:</p><pre class="programlisting">$ oc delete all --selector=template=scdf
$ oc delete cm --selector=template=scdf
$ oc delete secret --selector=template=scdf</pre></td></tr></table></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_download_and_run_the_spring_cloud_data_flow_shell" href="#_download_and_run_the_spring_cloud_data_flow_shell"></a>8.4&nbsp;Download and run the Spring Cloud Data Flow Shell</h2></div></div></div><p>Download and run the Shell, targeting the Data Flow Server exposed via a Route.</p><pre class="programlisting">$ wget http://repo.spring.io/release/org/springframework/cloud/spring-cloud-dataflow-shell/1.1.0.RELEASE/spring-cloud-dataflow-shell-1.1.0.RELEASE.jar
$ java -jar spring-cloud-dataflow-shell-1.1.0.RELEASE.jar --dataflow.uri=http://scdf-kafka-scdf.192.168.64.15.xip.io/

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/

1.1.0.RELEASE

Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</pre></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_registering_stream_applications_with_docker_resource" href="#_registering_stream_applications_with_docker_resource"></a>8.5&nbsp;Registering Stream applications with Docker resource</h2></div></div></div><p>Now register all out-of-the-box stream applications using the Docker resource type, built with the Kafka binder in bulk with the following command.</p><p>For more details, review how to <a class="link" href="http://docs.spring.io/spring-cloud-dataflow/docs/1.1.0.RELEASE/reference/html/spring-cloud-dataflow-register-apps.html" target="_top">register applications</a>.</p><pre class="programlisting">dataflow:&gt;app import --uri http://bit.ly/stream-applications-kafka-docker
Successfully registered applications: [source.tcp, sink.jdbc, source.http, sink.rabbit, source.rabbit, source.ftp, sink.gpfdist, processor.transform, source.loggregator, source.sftp, processor.filter, sink.cassandra, processor.groovy-filter, sink.router, source.trigger, sink.hdfs-dataset, processor.splitter, source.load-generator, processor.tcp-client, source.time, source.gemfire, source.twitterstream, sink.tcp, source.jdbc, sink.field-value-counter, sink.redis-pubsub, sink.hdfs, processor.bridge, processor.pmml, processor.httpclient, source.s3, sink.ftp, sink.log, sink.gemfire, sink.aggregate-counter, sink.throughput, source.triggertask, sink.s3, source.gemfire-cq, source.jms, source.tcp-client, processor.scriptable-transform, sink.counter, sink.websocket, source.mongodb, source.mail, processor.groovy-transform, source.syslog]</pre></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_deploy_a_simple_stream_in_the_shell" href="#_deploy_a_simple_stream_in_the_shell"></a>8.6&nbsp;Deploy a simple stream in the shell</h2></div></div></div><p>Create a simple <code class="literal">ticktock</code> stream definition and deploy it immediately using the following command:</p><pre class="programlisting">dataflow:&gt;stream create --name ticktock --definition "time | log" --deploy
Created new stream 'ticktock'
Deployment request has been sent</pre><p>Watch the OpenShift Console as the two application resources are created and the Pods are started.
Once the Docker images are pulled and the Pods are started up, you should see the Pods with dark blue circles:</p><div class="informalfigure"><div class="mediaobject"><img src="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/raw/master/spring-cloud-dataflow-server-openshift-docs/src/main/asciidoc/images/scdf-openshift-stream-deployed.png" alt="ticktock stream deployed"></div></div><p>You can also verify the deployed apps using the <code class="literal">oc tool</code></p><pre class="programlisting">$ oc get pods
NAME                     READY     STATUS      RESTARTS   AGE
...
ticktock-log-0-2-it3ja   1/1       Running     0          7m
ticktock-time-2-sxqnp    1/1       Running     0          6m</pre><p>To verify that the stream is working as expected, tail the logs of the <code class="literal">ticktock-log</code> app either using the OpenShift Console:</p><div class="informalfigure"><div class="mediaobject"><img src="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/raw/master/spring-cloud-dataflow-server-openshift-docs/src/main/asciidoc/images/scdf-openshift-stream-logs.png" alt="ticktock-log logs"></div></div><p>or the <code class="literal">oc</code> tool:</p><pre class="programlisting">$ oc logs -f ticktock-log
...
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 14:49:59
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 14:50:01
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 14:50:02
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 14:50:03
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 14:50:04
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 14:50:05
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 14:50:06
...</pre></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_registering_stream_applications_with_maven_resource" href="#_registering_stream_applications_with_maven_resource"></a>8.7&nbsp;Registering Stream applications with Maven resource</h2></div></div></div><p>The distinguishing feature of the Data Flow Server for OpenShift is that it has the capability to deploy applications registered with the Maven resource type
in addition to the Docker resource type. Using the <code class="literal">ticktock</code> stream example above, we will create a similar stream definition
but using the Maven resource versions of the apps.</p><p>For this example we will register the apps individually using the following command:</p><pre class="programlisting">dataflow:&gt;app register --type source --name time-mvn --uri maven://org.springframework.cloud.stream.app:time-source-kafka:1.1.0.RELEASE
Successfully registered application 'source:time-mvn'
dataflow:&gt;app register --type sink --name log-mvn --uri maven://org.springframework.cloud.stream.app:log-sink-kafka:1.1.0.RELEASE
Successfully registered application 'sink:log-mvn'</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>We couldn&#8217;t bulk import the Maven version of the apps as we did for the Docker versions because the app names
would conflict, as the names defined in the bulk import files are the same across resource types. Hence we register the
Maven apps with a <code class="literal">-mvn</code> suffix.</p></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_deploy_a_simple_stream_in_the_shell_2" href="#_deploy_a_simple_stream_in_the_shell_2"></a>8.8&nbsp;Deploy a simple stream in the shell</h2></div></div></div><p>Create a simple <code class="literal">ticktock-mvn</code> stream definition and deploy it immediately using the following command:</p><pre class="programlisting">dataflow:&gt;stream create --name ticktock-mvn --definition "time-mvn | log-mvn" --deploy
Created new stream 'ticktock-mvn'
Deployment request has been sent</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>There could be a slight delay once the above command is issued. This is due to the Maven artifacts being
resolved and cached locally. Depending on the size of the artifacts, this could take some time.</p></td></tr></table></div><p>Watch the OpenShift Console as the two application resources are created. Notice this time, that instead of the Pods
being started, that a <a class="link" href="https://docs.openshift.org/latest/dev_guide/builds.html" target="_top">Build</a> has been started instead.
The Build will execute and create a Docker image, using the default <a class="link" href="https://github.com/donovanmuller/spring-cloud-deployer-openshift/tree/v1.1.0.RELEASE/src/main/resources/" target="_top"><code class="literal">Dockerfile</code></a>,
containing the app. The resultant Docker image will be pushed to the internal OpenShift <a class="link" href="https://docs.openshift.org/latest/install_config/registry/index.html" target="_top">registry</a>,
where the deployment resource will be triggered when the image has been successfully pushed.
The <a class="link" href="https://docs.openshift.org/latest/dev_guide/deployments/how_deployments_work.html" target="_top">deployment</a> will then scale the app Pod up, starting the application.</p><div class="informalfigure"><div class="mediaobject"><img src="https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift/raw/master/spring-cloud-dataflow-server-openshift-docs/src/main/asciidoc/images/scdf-openshift-stream-mvn-deployed.png" alt="ticktock-maven stream deployed"></div></div><p>To verify that the stream is working as expected, tail the logs of the <code class="literal">ticktock-log-mvn</code> app using the <code class="literal">oc</code> tool:</p><pre class="programlisting">$ oc get pods
NAME                             READY     STATUS      RESTARTS   AGE
...
ticktock-mvn-log-mvn-0-1-agpl6   1/1       Running     0          4m
ticktock-mvn-log-mvn-1-build     0/1       Completed   0          1h
ticktock-mvn-time-mvn-1-12ikj    1/1       Running     0          1m
ticktock-mvn-time-mvn-1-build    0/1       Completed   0          1h

$ oc logs -f ticktock-mvn-log-mvn-0-1-agpl6
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 18:34:23
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 18:34:25
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 18:34:26
...  INFO 1 --- [afka-listener-1] log-sink                                 : 11/29/16 18:34:27</pre></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="getting-started.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="getting-started.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="_deploying_tasks_on_openshift.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Part&nbsp;III.&nbsp;Getting Started&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;9.&nbsp;Deploying Tasks on OpenShift</td></tr></table></div></body></html>
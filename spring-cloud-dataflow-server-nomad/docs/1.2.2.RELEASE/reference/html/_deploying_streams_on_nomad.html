<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>9.&nbsp;Deploying Streams on Nomad</title><link rel="stylesheet" type="text/css" href="css/manual-multipage.css"><meta name="generator" content="DocBook XSL Stylesheets V1.79.1"><link rel="home" href="index.html" title="Spring Cloud Data Flow Server for Nomad"><link rel="up" href="getting-started.html" title="Part&nbsp;III.&nbsp;Getting Started"><link rel="prev" href="getting-started.html" title="Part&nbsp;III.&nbsp;Getting Started"><link rel="next" href="_deploying_tasks_on_nomad.html" title="10.&nbsp;Deploying Tasks on Nomad"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">9.&nbsp;Deploying Streams on Nomad</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="getting-started.html">Prev</a>&nbsp;</td><th width="60%" align="center">Part&nbsp;III.&nbsp;Getting Started</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="_deploying_tasks_on_nomad.html">Next</a></td></tr></table><hr></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a name="_deploying_streams_on_nomad" href="#_deploying_streams_on_nomad"></a>9.&nbsp;Deploying Streams on Nomad</h2></div></div></div><p>The following guide assumes that you have a <a class="link" href="https://www.nomadproject.io/" target="_top">Nomad 0.5+</a> cluster available.
If you do not have a Nomad cluster available, see the next section which describes running a local Nomad for development/testing
otherwise continue to <a class="xref" href="_deploying_streams_on_nomad.html#installing-scdf" title="9.2&nbsp;Installing the Data Flow Server for Nomad">Section&nbsp;9.2, &#8220;Installing the Data Flow Server for Nomad&#8221;</a>.</p><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_a_local_nomad_cluster_with_vagrant_hashistack" href="#_a_local_nomad_cluster_with_vagrant_hashistack"></a>9.1&nbsp;A local Nomad cluster with Vagrant Hashistack</h2></div></div></div><p>There are a few ways to stand up a local Nomad cluster on your machine for testing.
For the purpose of this guide, the <a class="link" href="https://github.com/donovanmuller/hashistack-vagrant" target="_top">hashistack-vagrant</a> project will be used.</p><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/important.png"></td><th align="left">Important</th></tr><tr><td align="left" valign="top"><p>The <code class="literal">hashistack-vagrant</code> VM is configured by default with <code class="literal">2048 MB</code> of memory and <code class="literal">2</code> CPUs.
If you run into issues with job allocations failing because of resource starvation, you can tweak the
memory and CPU configuration in the <code class="literal">Vagrantfile</code>.</p><p>Please see the <a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-nomad/wiki/Resource-Allocations" target="_top">Resource Allocations</a>
section in the <code class="literal">spring-cloud-dataflow-server-nomad</code> project Wiki for more information.</p></td></tr></table></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_installation_and_getting_started" href="#_installation_and_getting_started"></a>9.1.1&nbsp;Installation and Getting Started</h3></div></div></div><p>Follow the <a class="link" href="https://github.com/donovanmuller/hashistack-vagrant#quickstart" target="_top">Quickstart</a>
section of the <a class="link" href="https://github.com/donovanmuller/hashistack-vagrant" target="_top">hashistack-vagrant</a>.</p><p>Once you have successfully started the Vagrant VM and (with <code class="literal">tmuxp load full-hashistack.yml</code>) "hashistack",
make sure you can use the <code class="literal">nomad</code> client to query the local instance:</p><pre class="programlisting">vagrant@hashistack:~$ nomad status
No running jobs</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>You could also install the <code class="literal">nomad</code> binary locally and connect to the Nomad client running inside the VM. For example
on Mac you could install Nomad with homebrew and add the <code class="literal">--address</code> option to your commands:</p><pre class="programlisting">$ brew install nomad
...
$ nomad status --address=http://172.16.0.2:4646
ID    Type     Priority  Status
scdf  service  50        running</pre></td></tr></table></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="installing-scdf" href="#installing-scdf"></a>9.2&nbsp;Installing the Data Flow Server for Nomad</h2></div></div></div><p>To install a Data Flow Server and supporting infrastructure components to Nomad we will use the provided Job specification provided
in the <a class="link" href="https://github.com/donovanmuller/spring-cloud-dataflow-server-nomad/tree/v1.2.2.RELEASE/src/etc/nomad" target="_top"><code class="literal">src/etc/nomad/</code></a>
directory of the project&#8217;s GitHub repository.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>This Job requires the <a class="link" href="https://www.nomadproject.io/docs/drivers/docker.html" target="_top">Docker</a> driver.</p></td></tr></table></div><p>This job specification includes the following tasks:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Spring Cloud Data Flow Server for Nomad</li><li class="listitem">Spring Cloud Data Flow Metrics Collector</li><li class="listitem">MySQL - as the datasource for the Data Flow Server</li><li class="listitem">Redis - for analytics support</li><li class="listitem">Kafka - as the Spring Cloud Stream default binder implementation</li></ul></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Tip"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Tip]" src="images/tip.png"></td><th align="left">Tip</th></tr><tr><td align="left" valign="top"><p>If you are not using the hashistack-vagrant VM, please adjust the <code class="literal">region</code> and <code class="literal">datacenters</code>
values in the <code class="literal">scdf.nomad</code> job specification file accordingly.</p></td></tr></table></div><p>Next, using the SSH session to the VM, run the job with:</p><pre class="programlisting">vagrant@hashistack:~$ nomad run https://raw.githubusercontent.com/donovanmuller/spring-cloud-dataflow-server-nomad/v1.2.2.RELEASE/src/etc/nomad/nexus.nomad
==&gt; Monitoring evaluation "491168de"
    Evaluation triggered by job "scdf"
    Allocation "63c64eaf" created: node "774539c7", group "scdf"
    Evaluation status changed: "pending" -&gt; "complete"
==&gt; Evaluation "491168de" finished with status "complete"</pre><p>Allow some time for the Docker images to be pulled and all containers to be started.
You can verify that all tasks have been successfully started by checking the
corresponding allocation status:</p><pre class="programlisting">vagrant@hashistack:~$ nomad alloc-status 63c64eaf
ID                  = 63c64eaf
Eval ID             = 491168de
Name                = scdf.scdf[0]
Node ID             = 774539c7
Job ID              = scdf
Client Status       = running
Client Description  = &lt;none&gt;
Desired Status      = run
Desired Description = &lt;none&gt;
Created At          = 08/01/17 20:58:44 UTC

Task "kafka" is "running"
Task Resources
CPU         Memory           Disk     IOPS  Addresses
25/500 MHz  507 MiB/512 MiB  500 MiB  0     kafka: 172.16.0.2:9092

Recent Events:
Time                   Type        Description
08/01/17 21:02:16 UTC  Started     Task started by client
08/01/17 21:01:59 UTC  Restarting  Task restarting in 16.424762972s
08/01/17 21:01:59 UTC  Terminated  Exit Code: 1, Exit Message: "Docker container exited with non-zero exit code: 1"
08/01/17 21:01:58 UTC  Started     Task started by client
08/01/17 21:01:40 UTC  Restarting  Task restarting in 16.967973166s
08/01/17 21:01:40 UTC  Terminated  Exit Code: 1, Exit Message: "Docker container exited with non-zero exit code: 1"
08/01/17 21:01:38 UTC  Started     Task started by client
08/01/17 20:58:44 UTC  Driver      Downloading image wurstmeister/kafka:0.10.1.0
08/01/17 20:58:44 UTC  Task Setup  Building Task Directory
08/01/17 20:58:44 UTC  Received    Task received by client

Task "mysql" is "running"
Task Resources
CPU        Memory           Disk     IOPS  Addresses
2/500 MHz  117 MiB/128 MiB  500 MiB  0     db: 172.16.0.2:3306

Recent Events:
Time                   Type        Description
08/01/17 21:00:50 UTC  Started     Task started by client
08/01/17 20:58:44 UTC  Driver      Downloading image mysql:5.6
08/01/17 20:58:44 UTC  Task Setup  Building Task Directory
08/01/17 20:58:44 UTC  Received    Task received by client

Task "redis" is "running"
Task Resources
CPU        Memory          Disk     IOPS  Addresses
3/256 MHz  6.2 MiB/64 MiB  500 MiB  0     redis: 172.16.0.2:6379

Recent Events:
Time                   Type        Description
08/01/17 20:58:57 UTC  Started     Task started by client
08/01/17 20:58:44 UTC  Driver      Downloading image redis:3-alpine
08/01/17 20:58:44 UTC  Task Setup  Building Task Directory
08/01/17 20:58:44 UTC  Received    Task received by client

Task "scdf-metrics-collector" is "running"
Task Resources
CPU          Memory           Disk     IOPS  Addresses
518/500 MHz  507 MiB/512 MiB  500 MiB  0     http: 172.16.0.2:8080

Recent Events:
Time                   Type        Description
08/01/17 21:02:10 UTC  Started     Task started by client
08/01/17 21:01:54 UTC  Restarting  Task restarting in 15.187972956s
08/01/17 21:01:54 UTC  Terminated  Exit Code: 1, Exit Message: "Docker container exited with non-zero exit code: 1"
08/01/17 21:01:34 UTC  Started     Task started by client
08/01/17 21:01:17 UTC  Restarting  Task restarting in 16.424762972s
08/01/17 21:01:17 UTC  Terminated  Exit Code: 1, Exit Message: "Docker container exited with non-zero exit code: 1"
08/01/17 21:00:57 UTC  Started     Task started by client
08/01/17 21:00:39 UTC  Restarting  Task restarting in 16.967973166s
08/01/17 21:00:39 UTC  Terminated  Exit Code: 1, Exit Message: "Docker container exited with non-zero exit code: 1"
08/01/17 21:00:16 UTC  Started     Task started by client

Task "scdf-server" is "running"
Task Resources
CPU        Memory           Disk     IOPS  Addresses
5/500 MHz  323 MiB/384 MiB  500 MiB  0     http: 172.16.0.2:9393

Recent Events:
Time                   Type            Description
08/01/17 21:11:26 UTC  Started         Task started by client
08/01/17 21:11:08 UTC  Restarting      Task restarting in 17.905628447s
08/01/17 21:11:08 UTC  Terminated      Exit Code: 137, Exit Message: "Docker container exited with non-zero exit code: 137"
08/01/17 21:05:27 UTC  Started         Task started by client
08/01/17 21:05:09 UTC  Restarting      Task restarting in 18.119676483s
08/01/17 21:05:09 UTC  Driver Failure  failed to initialize task "scdf-server" for alloc "63c64eaf-5a43-3e18-8e55-0134f8c18f93": Failed to pull `donovanmuller/spring-cloud-dataflow-server-nomad:1.2.3.RELEASE`: API error (404): {"message":"manifest for donovanmuller/spring-cloud-dataflow-server-nomad:1.2.3.RELEASE not found"}
08/01/17 21:05:05 UTC  Driver          Downloading image donovanmuller/spring-cloud-dataflow-server-nomad:1.2.3.RELEASE
08/01/17 21:04:47 UTC  Restarting      Task restarting in 17.088216893s
08/01/17 21:04:47 UTC  Driver Failure  failed to initialize task "scdf-server" for alloc "63c64eaf-5a43-3e18-8e55-0134f8c18f93": Failed to pull `donovanmuller/spring-cloud-dataflow-server-nomad:1.2.3.RELEASE`: API error (404): {"message":"manifest for donovanmuller/spring-cloud-dataflow-server-nomad:1.2.3.RELEASE not found"}
08/01/17 21:04:42 UTC  Driver          Downloading image donovanmuller/spring-cloud-dataflow-server-nomad:1.2.3.RELEASE

Task "zookeeper" is "running"
Task Resources
CPU        Memory          Disk     IOPS  Addresses
2/500 MHz  45 MiB/128 MiB  500 MiB  0     zookeeper: 172.16.0.2:2181
                                          follower: 172.16.0.2:2888
                                          leader: 172.16.0.2:3888

Recent Events:
Time                   Type        Description
08/01/17 21:02:12 UTC  Started     Task started by client
08/01/17 20:58:44 UTC  Driver      Downloading image digitalwonderland/zookeeper:latest
08/01/17 20:58:44 UTC  Task Setup  Building Task Directory
08/01/17 20:58:44 UTC  Received    Task received by client

...</pre><p>or alternatively check the health status of all services using the Consul UI:</p><div class="informalfigure"><div class="mediaobject"><img src="https://github.com/donovanmuller/spring-cloud-dataflow-server-nomad/raw/master/spring-cloud-dataflow-server-nomad-docs/src/main/asciidoc/images/scdf-nomad-up.jpg" alt="Data Flow Server and components up"></div></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If you are using a local <code class="literal">nomad</code> binary you can reference the remote <code class="literal">scdf.nomad</code> file directly.</p><pre class="programlisting">$ nomad run --address=http://172.16.0.2:4646 https://raw.githubusercontent.com/donovanmuller/spring-cloud-dataflow-server-nomad/v1.2.2.RELEASE/src/etc/nomad/scdf.nomad
...</pre></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_download_and_run_the_spring_cloud_data_flow_shell" href="#_download_and_run_the_spring_cloud_data_flow_shell"></a>9.3&nbsp;Download and run the Spring Cloud Data Flow Shell</h2></div></div></div><p>Download and run the Shell, targeting the Data Flow Server exposed via a Fabio route.</p><pre class="programlisting">$ wget http://repo.spring.io/release/org/springframework/cloud/spring-cloud-dataflow-shell/1.2.3.RELEASE/spring-cloud-dataflow-shell-1.2.3.RELEASE.jar
$ java -jar spring-cloud-dataflow-shell-1.2.3.RELEASE.jar \
  --dataflow.uri=http://scdf-server.hashistack.vagrant/ \
  --dataflow.username=user \
  --dataflow.password=password

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/

1.2.3.RELEASE

Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>Security is enabled by default. See the <a class="link" href="http://docs.spring.io/spring-cloud-dataflow/docs/1.2.3.RELEASE/reference/htmlsingle/#configuration-security-single-user-authentication" target="_top">Security configuration section</a> for more information.
There are two default users created:</p><div class="informaltable"><table class="informaltable" style="border-collapse: collapse;border-top: 1px solid ; border-bottom: 1px solid ; border-left: 1px solid ; border-right: 1px solid ; "><colgroup><col class="col_1"><col class="col_2"></colgroup><thead><tr><th style="border-right: 1px solid ; border-bottom: 1px solid ; " align="left" valign="top">Username</th><th style="border-bottom: 1px solid ; " align="left" valign="top">Password</th></tr></thead><tbody><tr><td style="border-right: 1px solid ; border-bottom: 1px solid ; " align="left" valign="top"><p>user</p></td><td style="border-bottom: 1px solid ; " align="left" valign="top"><p>password</p></td></tr><tr><td style="border-right: 1px solid ; " align="left" valign="top"><p>admin</p></td><td style="" align="left" valign="top"><p>admin</p></td></tr></tbody></table></div></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_registering_stream_applications_with_docker_resource" href="#_registering_stream_applications_with_docker_resource"></a>9.4&nbsp;Registering Stream applications with Docker resource</h2></div></div></div><p>Now register all out-of-the-box stream applications using the Docker resource type, built with the Kafka binder in bulk with the following command.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Tip"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Tip]" src="images/tip.png"></td><th align="left">Tip</th></tr><tr><td align="left" valign="top"><p>For more details, review how to <a class="link" href="http://docs.spring.io/spring-cloud-dataflow/docs/1.2.3.RELEASE/reference/html/spring-cloud-dataflow-register-apps.html" target="_top">register applications</a>.</p></td></tr></table></div><pre class="programlisting">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-kafka-10-docker
Successfully registered applications: [source.tcp, sink.jdbc, source.http, sink.rabbit, source.rabbit, source.ftp, sink.gpfdist, processor.transform, source.loggregator, source.sftp, processor.filter, sink.cassandra, processor.groovy-filter, sink.router, source.trigger, sink.hdfs-dataset, processor.splitter, source.load-generator, processor.tcp-client, source.time, source.gemfire, source.twitterstream, sink.tcp, source.jdbc, sink.field-value-counter, sink.redis-pubsub, sink.hdfs, processor.bridge, processor.pmml, processor.httpclient, source.s3, sink.ftp, sink.log, sink.gemfire, sink.aggregate-counter, sink.throughput, source.triggertask, sink.s3, source.gemfire-cq, source.jms, source.tcp-client, processor.scriptable-transform, sink.counter, sink.websocket, source.mongodb, source.mail, processor.groovy-transform, source.syslog]</pre></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_deploy_a_simple_stream_in_the_shell" href="#_deploy_a_simple_stream_in_the_shell"></a>9.5&nbsp;Deploy a simple stream in the shell</h2></div></div></div><p>Create a simple <code class="literal">ticktock</code> stream definition and deploy it immediately using the following command:</p><pre class="programlisting">dataflow:&gt;stream create --name ticktock --definition "time | log" --deploy
Created new stream 'ticktock'
Deployment request has been sent</pre><p>Verify the deployed apps using the by checking the status of the apps using the Shell:</p><div class="informalfigure"><div class="mediaobject"><img src="https://github.com/donovanmuller/spring-cloud-dataflow-server-nomad/raw/master/spring-cloud-dataflow-server-nomad-docs/src/main/asciidoc/images/scdf-nomad-stream-deployed.jpg" alt="ticktock streamd deployed"></div></div><p>To verify that the stream is working as expected, tail the logs of the <code class="literal">ticktock-log</code> using <code class="literal">nomad</code>:</p><pre class="programlisting">vagrant@hashistack:~$ nomad logs 71f7aba1
...
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 14:49:59
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 14:50:01
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 14:50:02
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 14:50:03
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 14:50:04
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 14:50:05
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 14:50:06
...</pre></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_registering_stream_applications_with_maven_resource" href="#_registering_stream_applications_with_maven_resource"></a>9.6&nbsp;Registering Stream applications with Maven resource</h2></div></div></div><p>The Data Flow Server for Nomad also supports apps registered with a Maven resource URI
in addition to the Docker resource type. Using the <code class="literal">ticktock</code> stream example above, we will create a similar stream definition
but using the Maven resource versions of the apps.</p><p>For this example we will register the apps individually using the following command:</p><pre class="programlisting">dataflow:&gt;app register --type source --name time-mvn --uri maven://org.springframework.cloud.stream.app:time-source-kafka:1.2.3.RELEASE
Successfully registered application 'source:time-mvn'
dataflow:&gt;app register --type sink --name log-mvn --uri maven://org.springframework.cloud.stream.app:log-sink-kafka:1.2.3.RELEASE
Successfully registered application 'sink:log-mvn'</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>We couldn&#8217;t bulk import the Maven version of the apps as we did for the Docker versions because the app names
would conflict, as the names defined in the bulk import files are the same across resource types. Hence we register the
Maven apps with a <code class="literal">-mvn</code> suffix.</p></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_deploy_a_simple_stream_in_the_shell_2" href="#_deploy_a_simple_stream_in_the_shell_2"></a>9.7&nbsp;Deploy a simple stream in the shell</h2></div></div></div><p>Create a simple <code class="literal">ticktock-mvn</code> stream definition and deploy it immediately using the following command:</p><pre class="programlisting">dataflow:&gt;stream create --name ticktock-mvn --definition "time-mvn | log-mvn" --deploy
Created new stream 'ticktock-mvn'
Deployment request has been sent</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>There could be a slight delay once the above command is issued. This is due to the Maven artifacts being
resolved and cached locally. Depending on the size of the artifacts, this could take some time.</p></td></tr></table></div><p>To verify that the stream is working as expected, tail the logs of the <code class="literal">ticktock-mvn-log-mvn</code> using <code class="literal">nomad</code>:</p><pre class="programlisting">$ nomad logs -f 3f474cc7
...
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 18:34:23
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 18:34:25
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 18:34:26
...  INFO 1 --- [afka-listener-1] log-sink                                 : 02/08/17 18:34:27</pre></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="getting-started.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="getting-started.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="_deploying_tasks_on_nomad.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Part&nbsp;III.&nbsp;Getting Started&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;10.&nbsp;Deploying Tasks on Nomad</td></tr></table></div></body></html>